{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "#caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
    "import sys\n",
    "import os\n",
    "#print caffe_root\n",
    "#sys.path.insert(0, caffe_root + 'python')\n",
    "sys.path.append('/home/young/caffe-master/python/')\n",
    "sys.path.append('/usr/lib/python2.7/dist-packages/')\n",
    "\n",
    "import caffe\n",
    "\n",
    "#rootdir = os.getcwd()\n",
    "#print rootdir\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define unpickle file to read cifar10 data from python pickle file\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, 'rb')\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "# get mean ndarray from mean.binaryproto file by convert the file to .npy file\n",
    "\n",
    "blob = caffe.proto.caffe_pb2.BlobProto()\n",
    "data = open( '/home/young/Desktop/hashmodel/Zcifar10_hash/dataset/mean.binaryproto', 'rb' ).read()\n",
    "blob.ParseFromString(data)\n",
    "arr = np.array( caffe.io.blobproto_to_array(blob) )\n",
    "mean = arr[0]\n",
    "\n",
    "print mean.shape\n",
    "#channel_swap = [2,1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.096\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rootdir = '/home/young/Desktop/hashmodel'\n",
    "rootdata = rootdir + '/Zcifar10_hash/dataset/'\n",
    "TEST_DATA_FILE = rootdata + 'test_batch'\n",
    "test_num = 10000\n",
    "test  = unpickle(TEST_DATA_FILE)\n",
    "test_data = test['data']\n",
    "test_labels = test['labels']\n",
    "test_caffe_in = test_data.reshape(test_num,  3, 32, 32)\n",
    "test_caffe_in = np.array(test_caffe_in, np.float32) ##!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "for k in range(test_num):\n",
    "    test_caffe_in[k][0] = test_caffe_in[k][0] - mean[0]\n",
    "    test_caffe_in[k][1] = test_caffe_in[k][1] - mean[1]\n",
    "    test_caffe_in[k][2] = test_caffe_in[k][2] - mean[2]\n",
    "\n",
    "\n",
    "train_num = 50000\n",
    "train_caffe_in = np.ndarray((train_num, 3, 32, 32), dtype=np.uint8)\n",
    "train_labels = np.ndarray((train_num, ), dtype=np.uint8)\n",
    "\n",
    "for i in xrange(5):\n",
    "    TRAIN_DATA_FILE = rootdata + 'data_batch_' + str(i+1)\n",
    "    num = 10000\n",
    "    train_i  = unpickle(TRAIN_DATA_FILE)\n",
    "    train_i_data = train_i['data']\n",
    "    train_i_label = train_i['labels']\n",
    "    train_i_nd = train_i_data.reshape(num,  3, 32, 32)\n",
    "    train_caffe_in[i*num:(i+1)*num, :, :, :] = train_i_nd\n",
    "    train_labels[i*num:(i+1)*num] = train_i_label\n",
    "\n",
    "train_caffe_in = np.array(train_caffe_in, np.float32)\n",
    "for k in range(train_num):\n",
    "    train_caffe_in[k][0] = train_caffe_in[k][0] - mean[0]\n",
    "    train_caffe_in[k][1] = train_caffe_in[k][1] - mean[1]\n",
    "    train_caffe_in[k][2] = train_caffe_in[k][2] - mean[2]\n",
    "    \n",
    "# data processing needed here, centre, chanel change\n",
    "rootmodel = rootdir + '/cifar10-32/'\n",
    "net = caffe.Net(rootmodel + 'cifar10_32.prototxt', \\\n",
    "                rootmodel + 'cifar10_full_hash32_iter_70000.caffemodel')\n",
    "net.set_mode_gpu() # use gpu model\n",
    "\n",
    "#########################################################\n",
    "#net.set_channel_swap(net.inputs[0], channel_swap)\n",
    "#net.set_mean(net.inputs[0], mean)\n",
    "#########################################################\n",
    "\n",
    "test_out = net.forward_all(data = train_caffe_in)\n",
    "\n",
    "test_prob = test_out['prob']\n",
    "\n",
    "tmp = 0\n",
    "for i in xrange(train_num):\n",
    "    if (test_prob[i].argmax() == train_labels[i]):\n",
    "        tmp = tmp+1\n",
    "print tmp*100.0/train_num\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 16 bit hashing\n",
      "processing 24 bit hashing\n",
      "processing 32 bit hashing\n",
      "processing 48 bit hashing\n",
      "processing 64 bit hashing\n",
      "processing 128 bit hashing\n",
      "processing 256 bit hashing\n",
      "processing 512 bit hashing\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# iterate all the bits from 16~512\n",
    "from scipy.io import savemat\n",
    "\n",
    "rootdir = '/home/young/Desktop/hashmodel'\n",
    "\n",
    "netfile = ['16', '24', '32', '48', '64', '128', '256', '512']\n",
    "modelfile = ['cifar10_full_hash16_iter_70000.caffemodel', 'cifar10_full_hash24_iter_70000.caffemodel', \\\n",
    "             'cifar10_full_hash32_iter_70000.caffemodel', 'cifar10_full_hash48_iter_70000.caffemodel', \\\n",
    "             'cifar10_full_hash64_iter_70000.caffemodel', 'cifar10_full_hash128_iter_70000.caffemodel', \\\n",
    "             'cifar10_full_hash256_iter_70000.caffemodel', 'cifar10_full_feature512_iter_70000.caffemodel']\n",
    "\n",
    "\n",
    "roothash = rootdir + '/Zcifar10_hash/hash/'\n",
    "for i in xrange(8):\n",
    "    print 'processing %s bit hashing' % netfile[i]\n",
    "    rootmodel = rootdir + '/cifar10-' + netfile[i] + '/'\n",
    "    net = caffe.Net(rootmodel + 'cifar10_' + netfile[i] + '.prototxt', \\\n",
    "                    rootmodel + modelfile[i])\n",
    "    net.set_mode_gpu() # use gpu model\n",
    "    test_out = net.forward_all(data = test_caffe_in)\n",
    "    train_out = net.forward_all(data = train_caffe_in)\n",
    "    #hash = np.vstack((test_out.get('hash'+netfile[i]), train_out.get('hash'+netfile[i])))\n",
    "    #savemat(roothash+'hash'+netfile[i]+'.mat', {'hash':hash})\n",
    "    test_hash = test_out.get('hash'+netfile[i])\n",
    "    train_hash = train_out.get('hash'+netfile[i])\n",
    "    savemat(roothash+'hash'+netfile[i]+'.mat', {'testh':test_hash, 'trainh':train_hash})\n",
    "\"\"\"    \n",
    "label = np.ndarray((test_num+train_num,), dtype = np.uint8)\n",
    "label[0:test_num] = test_labels\n",
    "label[test_num:test_num+train_num] = train_labels\n",
    "savemat(roothash+'label.mat', {'label':label})\n",
    "\"\"\"\n",
    "savemat(roothash+'label.mat', {'test_label':test_labels, 'train_label':train_labels})\n",
    "\n",
    "\n",
    "print 'Done'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
