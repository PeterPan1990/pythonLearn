{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Make sure that caffe is on the python path:\n",
    "#caffe_root = '../'  # this file is expected to be in {caffe_root}/examples\n",
    "import sys\n",
    "import os\n",
    "#print caffe_root\n",
    "#sys.path.insert(0, caffe_root + 'python')\n",
    "sys.path.append('/home/young/caffe-master/python/')\n",
    "sys.path.append('/usr/lib/python2.7/dist-packages/')\n",
    "\n",
    "import caffe\n",
    "\n",
    "#rootdir = os.getcwd()\n",
    "#print rootdir\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.03\n"
     ]
    }
   ],
   "source": [
    "# use classicication to test the extraction\n",
    "\n",
    "# read image data from binary file use numpy.fromstring() and read()\n",
    "rootdir = '/home/young/Desktop/hashmodel'\n",
    "rootdata = rootdir + '/Zmnist_hash/dataset/'\n",
    "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
    "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
    "test_num = 10000\n",
    "with open(TEST_DATA_FILE, 'rb') as f:\n",
    "    f.read(16)\n",
    "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
    "    \n",
    "with open(TEST_LABEL_FILE, 'rb') as f:\n",
    "    f.read(8)\n",
    "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
    "# manually scale data instead of using `caffe.io.Transformer`\n",
    "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28) * 0.00390625\n",
    "\n",
    "net = caffe.Net('/home/young/Desktop/hashmodel/mnist-64/lenet_64.prototxt', \\\n",
    "                '/home/young/Desktop/hashmodel/mnist-64/lenet_hash64_iter_20000.caffemodel')\n",
    "net.set_mode_gpu() # use gpu model\n",
    "\n",
    "test_out = net.forward_all(data = test_caffe_in)\n",
    "test_prob = test_out['prob']\n",
    "\n",
    "tmp = 0\n",
    "for i in xrange(test_num):\n",
    "    if (test_prob[i].argmax() == test_labels[i]):\n",
    "        tmp = tmp+1\n",
    "print tmp*100.0/test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 28, 28)\n",
      "(60000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# read image data from binary file use numpy.fromstring() and read()\n",
    "rootdata = rootdir + '/Zmnist_hash/dataset/'\n",
    "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
    "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
    "test_num = 10000\n",
    "with open(TEST_DATA_FILE, 'rb') as f:\n",
    "    f.read(16)\n",
    "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
    "    \n",
    "with open(TEST_LABEL_FILE, 'rb') as f:\n",
    "    f.read(8)\n",
    "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
    "# manually scale data instead of using `caffe.io.Transformer`\n",
    "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28)\n",
    "print test_caffe_in.shape\n",
    "\n",
    "TRAIN_DATA_FILE = rootdata + 'train-images-idx3-ubyte'\n",
    "TRAIN_LABEL_FILE = rootdata + 'train-labels-idx1-ubyte'\n",
    "train_num = 60000\n",
    "with open(TRAIN_DATA_FILE, 'rb') as f:\n",
    "    f.read(16) # skip the header\n",
    "    train_raw_data = np.fromstring(f.read(train_num * 28*28), dtype=np.uint8)\n",
    "\n",
    "with open(TRAIN_LABEL_FILE, 'rb') as f:\n",
    "    f.read(8) # skip the header\n",
    "    train_labels = np.fromstring(f.read(train_num), dtype=np.uint8)\n",
    "# manually scale data instead of using `caffe.io.Transformer`\n",
    "train_caffe_in = train_raw_data.reshape(train_num, 1, 28, 28)\n",
    "\n",
    "print train_caffe_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import savemat\n",
    "savemat('label.mat', {'test_label':test_labels, 'train_label':train_labels})\n",
    "\n",
    "savemat('data.mat', {'test':test_caffe_in, 'train':train_caffe_in})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 16 bit hashing\n",
      "processing 24 bit hashing\n",
      "processing 32 bit hashing\n",
      "processing 48 bit hashing\n",
      "processing 64 bit hashing\n",
      "processing 128 bit hashing\n",
      "processing 256 bit hashing\n",
      "processing 512 bit hashing\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# iterate all the bits from 16~512\n",
    "from scipy.io import savemat\n",
    "\n",
    "rootdir = '/home/young/Desktop/hashmodel'\n",
    "\n",
    "netfile = ['16', '24', '32', '48', '64', '128', '256', '512']\n",
    "modelfile = ['lenet_hash16_iter_20000.caffemodel', 'lenet_hash24_iter_20000.caffemodel', \\\n",
    "             'lenet_hash32_iter_20000.caffemodel', 'lenet_hash48_iter_20000.caffemodel', \\\n",
    "             'lenet_hash64_iter_20000.caffemodel', 'lenet_hash128_iter_20000.caffemodel', \\\n",
    "             'lenet_hash256_iter_20000.caffemodel', 'lenet_feature512_iter_20000.caffemodel']\n",
    "\n",
    "# read image data from binary file use numpy.fromstring() and read()\n",
    "rootdata = rootdir + '/Zmnist_hash/dataset/'\n",
    "TEST_DATA_FILE = rootdata + 't10k-images-idx3-ubyte'\n",
    "TEST_LABEL_FILE = rootdata + 't10k-labels-idx1-ubyte'\n",
    "test_num = 10000\n",
    "with open(TEST_DATA_FILE, 'rb') as f:\n",
    "    f.read(16)\n",
    "    test_raw_data = np.fromstring(f.read(test_num * 28*28), dtype = np.uint8)\n",
    "    \n",
    "with open(TEST_LABEL_FILE, 'rb') as f:\n",
    "    f.read(8)\n",
    "    test_labels = np.fromstring(f.read(test_num), dtype = np.uint8)\n",
    "# manually scale data instead of using `caffe.io.Transformer`\n",
    "test_caffe_in = test_raw_data.reshape(test_num, 1, 28, 28) * 0.00390625\n",
    "\n",
    "TRAIN_DATA_FILE = rootdata + 'train-images-idx3-ubyte'\n",
    "TRAIN_LABEL_FILE = rootdata + 'train-labels-idx1-ubyte'\n",
    "train_num = 60000\n",
    "with open(TRAIN_DATA_FILE, 'rb') as f:\n",
    "    f.read(16) # skip the header\n",
    "    train_raw_data = np.fromstring(f.read(train_num * 28*28), dtype=np.uint8)\n",
    "\n",
    "with open(TRAIN_LABEL_FILE, 'rb') as f:\n",
    "    f.read(8) # skip the header\n",
    "    train_labels = np.fromstring(f.read(train_num), dtype=np.uint8)\n",
    "# manually scale data instead of using `caffe.io.Transformer`\n",
    "train_caffe_in = train_raw_data.reshape(train_num, 1, 28, 28) * 0.00390625 \n",
    "\n",
    "\n",
    "\n",
    "roothash = rootdir + '/Zmnist_hash/hash/'\n",
    "\n",
    "for i in xrange(8):\n",
    "    print 'processing %s bit hashing' % netfile[i]\n",
    "    rootmodel = rootdir + '/mnist-' + netfile[i] + '/'\n",
    "    net = caffe.Net(rootmodel + 'lenet_' + netfile[i] + '.prototxt', \\\n",
    "                    rootmodel + modelfile[i])\n",
    "    net.set_mode_gpu() # use gpu model\n",
    "    test_out = net.forward_all(data = test_caffe_in)\n",
    "    train_out = net.forward_all(data = train_caffe_in)\n",
    "    #hash = np.vstack((test_out.get('hash'+netfile[i]), train_out.get('hash'+netfile[i])))\n",
    "    test_hash = test_out.get('hash'+netfile[i])\n",
    "    train_hash = train_out.get('hash'+netfile[i])\n",
    "    savemat(roothash+'hash'+netfile[i]+'.mat', {'testh':test_hash, 'trainh':train_hash})\n",
    "\n",
    "#label = np.ndarray((test_num+train_num,), dtype = np.uint8)\n",
    "#label[0:test_num] = test_labels\n",
    "#label[test_num:test_num+train_num] = train_labels\n",
    "savemat(roothash+'label.mat', {'test_label':test_labels, 'train_label':train_labels})\n",
    "\n",
    "print 'Done'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
